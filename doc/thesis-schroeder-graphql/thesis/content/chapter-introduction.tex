%! Author = Yannick Schröder
%! Date = 13.05.20

%************************************************
% Grundlagen
%************************************************
\chapter{Einleitung}
\label{sec:requirements}

Ziel dieser Arbeit ist die Evaluierung von Verfahren, welche eine sichere, effiziente und leichte Nutzung der Kommunikationsschnittstellen 
zwischen Client, Server und Datenbank ermöglichen soll und wenn möglich die Integration eines dieser Verfahren
in die von Marcus Riemer entwickelte Lehr-Entwicklungsumgebung BlattWerkzeug (siehe~\ref{sec:basics}),
In den nächsten Kapiteln sind die Probleme des derzeitigen Verfahrens und die Anforderungen an die Nutzung der Kommunikationsschnittstellen näher beschrieben.
%Das im Rahmen dieser Arbeit zu entwickelnde Tool soll sich in BlattWerkzeug integrieren und die aktuellen Kommunikationsschnittstellen wenn möglich ersetzen.

%************************************************
% Status Quo
%************************************************
\chapter{Grundlagen}
\label{sec:basics}
In diesem Kapitel werden grundlegende Inhalte beschrieben, welche im späteren Verlauf der Arbeit aufgegriffen 
und bei Erläuterungen und Code-Beispielen als Wissensbasis vorausgesetzt werden. Viele dieser Inhalte sind aktuell Gegenstand
des von Marcus Riemers entwickelten Systems und gehören somit für die Schaffung und Umsetzung von Verbesserungen grundlegend verstanden.
%Nicht spezifisch auf Blattwerzeuge werden!! Kleines Beispiel ist erlaubt (Begriff Blattwerzeug wird nicht erwähnt).
\section{REST API}
\label{sec:basics:restapi}
Der Begriff REST wurde erstmalig in der Dissertation "Architectural Styles and the Design of 
Network-based Software Architectures" von Roy Thomas Fielding im Jahr 2000 geprägt~\cite{fielding-dissertation}.
Er beschreibt REST als einen Architekturstil für verteilte Systeme, welcher in eine einheitliche Schnittstelle für Kommunikation mündet.
Dieser Architekturstil oder auch Programmierparadigma, wird durch verschiedene Software-Engineering-Prinzipien und Beschränkungen definiert.
Im Folgenden werden die Prizipien von REST näher erläutert.

\subsection{Client-Server-Modell}
Der Ausgangspunkt des Client-Server-Modells ist eine Trennung der Benutzeroberfläche von der Datenhaltung/-verwertung.
Es verbessert die Portabilität der Benutzeroberfläche in Bezug auf die Anbindung an verschiedene Datenhaltungs/-verwertungs Systeme,
also die Wiederverwendbarkeit und die Skalierbarkeit aufgrund der Vereinfachung der Serverkomponenten.

\subsection{Zustandslosigkeit}
Zustandslosigkeit ist eine Beschränkung in Bezug auf die Kommunikation zwischen Server und Client.
Anfragen vom Client müssen alle Informationen beinhalten um diese interpretieren zu können.
Insbesondere werden Anfragen ohne Bezug zu früheren Anfragen behandelt und keine Sitzungsinformationen ausgetauscht bzw. verwaltet.
Diese befinden sich ausschließlich auf dem Client. 

Anfragen können unabhängig voneinander betrachtet werden, da jede Anfrage für sich eine vollständige Anforderung an den Server beschreibt.
Zudem kann einfacher auf den Misserfolg einer Anfrage reagiert werden, als auf eine erfolglose Kette von zusammenhängenden Anfragen
und es ist nicht vonnöten Zwischenzustände bzw. Status zu speichern, welche die Ressourcenauslastung erhöhen würde.
Dies kann jedoch zu einer verringerten Netzwerkleistung führen, aufgrund von Zusatzinformationen, 
die sich bei mehreren verschiedenen Anfragen wiederholen und erneut mit gesendet werden müssen.

\subsection{Cache}
In Hinblick auf das Verbessern der Netzwerkleistung wurde ein Cache als Einschränkung hinzugefügt.
Diese Einschränkung setzt voraus, dass Daten aus einer Antwort vom Server implizit oder explizit als cachefähig oder nicht cachefähig gekennzeichnet werden.
Werden Daten in einer Antwort auf eine Anfrage als cachefähig gekennzeichnet, kann der Client diese Information speichern und erhält das Recht diese
bei einer späteren gleichwertigen Anfrage, wiederzuverwenden.
Somit können Anfragen effizienter behandelt bzw. ganz durch eine direkt aus dem Cache geladene Antwort ersetzt werden.

\subsection{Einheitliche Schnittstelle}
Ein zentrales Merkmal von REST ist die einheitliche und vom Dienst entkoppelte Schnittstelle.
Durch eine einheitliche Komponentenschnittstelle wird die Sichtbarkeit der einzelnen Interaktionen erhöht.
Das hat zu Folge, dass anwendungsspezifische Daten in einer standardisierten Form übertragen werden müssen,
wodurch die Effizienz der Datenübertragung Mängel aufwerfen kann.

\subsection{Layered System}
Der Layered System Software-Architekturstil beschreibt das Prinzip eines hierachisch in Schichten aufgebauten Systems.
Jede Komponente kann ausschließlich Schichten "sehen" mit denen sie interagiert.
Eine Anwendung kann dadurch ihre Anforderungen auf mehrere Schichten verteilen, wie zum Beispiel bei einer Anwendung die ihre API auf Server A anbietet,
die Daten auf Server B lagert und einen Authetifizierungsdienst von Server C nutzt.
Nachteile dieser Einschränkung spiegeln sich in gestiegener Komplexität der Gesamtarchitektur und kommunikativem Overhead wieder.


Desweiteren gibt es noch eine optionale Einschränkung auf die nicht näher eingegangen wird.
%Als Entwickler einer Anwendung stellt Modularität ein von Beginn an bedachtes Kalkül dar.
Alles in allem bietet REST als Achitekturstil Grundlagen für Entwicklung eines modularen, verteilten und einfach mit zu interagierendem Systems.
TODO: Abschlusswort finden!

\section{GraphQL}
\label{sec:basics:graphql}
Das wesentliche Motiv bei der Nutzung des Internets ist die Informationsaufnahme~\cite{statista-1}\cite{ard-zdf}.
Informationen werden auf unzähligen Webapplikationen bereitgestellt, die jeder mit einem Internetzugang einsehen kann,
solange der Zugriff auf die Informationen nicht sonderlich geschützt wird.
Um persistente und sensible Daten gesichert und nicht für Jedermann zugreifbar lagern zu können, werden sie \emph{serverseitig} gehalten.
Möchte man diese Daten zusätzlich Filtern, Sortieren oder mehrere Datensätze miteinander verknüpfen, wird eine Datenbank benötigt.
Eine Datei in der die Daten abgelegt werden, wäre auch eine Option, allerdings müsste man alle Methoden zum Filtern, Sortieren und Verknüpfen
selber implementieren und damit das Rad neu erfinden.

Die in einer Datenbank gespeicherten Informationen sind also aus Nutzersicht nur über eine Anfrage an den Sever abrufbar.
Somit ist der Server das Bindeglied zwischen einem Client und der Datenbank und kümmert sich um Aufgaben wie Authentifizierung des Nutzers
und Überprüfung der Authorisierung bezüglich der angefragten Daten, aber auch um die Zusammensetzung und Ausführung von Datenbankabfragen.
Daraus geht hervor das ein Client nur begrenzten Zugriff bekommt, da die Ausführung von vordefinierten Datenbanktransaktionen
lediglich angefragt werden kann. Werden die vordefinierten Transaktionen den Bedarf an Informationen nicht gerecht, müssen neue Transaktionen entwickelt
oder mithilfe von mehreren Anfragen die Daten zusammengesammelt werden.

Dieser Entwicklungsaufwand könnte verringert werden, indem der Client mehr Flexibilität, Verantwortung und Effizienz besitzen würde,
z.B. durch eine direkte Anbindung an die Datenbank.
Er könnte alle benötigten Daten dann direkt und effizient z.B. per SQL Query aus der Datenbank auslesen.
Jedoch würde dieser Ansatz viele Gefahren mit sich bringen. Ein Client der direkten Datenbankzugriff erlangt,
könnte unerwünschte Transaktionen in der Datenbank ausführen, wodurch die konsistenz der Daten verletzt,
Einträge gar gelöscht oder sensible Daten anderer Nutzer abgefragt werden könnte. Also sollten Zugriffsbeschränkungen erteilt werden, die
auf der Datenbankschicht realisiert werden, da Clientseitiger Code nach belieben vom Nutzer eingesehen und verändert werden kann.
Hinzu kommen weitere Herausforderungen wenn die verbindung zur Datenbank veröffentlicht wurde,
wie das Schützen vor exessiver Nutzung oder denial of service (Dos) Attacken.
Alles in allem ist das ein Verfahren, von dem dringend abgeraten wird, da es in den wenigsten Fällen nutzbringend und sicher gehandhabt werden kann~\cite{client-to-database}.

%Nutzung einer statischen Schnittstelle zu einer sich ändernden Implementierung

GraphQL könnte als Lösung für die aufgeführten Probleme fungieren, besonders in Bezug auf Flexibilität, Verantwortung und Effizienz~\cite{graphql-scalablepath}.
Es handelt sich um eine Abfragesprache für APIs
und eine Laufzeitumgebnung, zum Ausführen dieser Abfragen und Wiedergeben von Daten unter Verwendung eines von für die Daten definierten Typensystems.
Es ist an keinerlei Datenbanksysteme oder Speicherengines gebunden und lässt sich gut mit vorhandenem Code und Daten verbinden.

Ein GraphQL Service ensteht durch das Definieren von Typen, vergleichbar mit Datenbanktabellen. Im Gegensatz zu einem Datenbank Schema,
ermöglicht das Typsystem von GraphQL zu jedem Typen Argumente zu definieren, die wiederum einer Funktion (Resolver) übergeben werden kann, die aufgerufen wird, wenn das Feld
im Kontext einer Query aufgelöst werden soll. Desweiteren lassen sich zu jedem Feld eines Typs, wie bei Datenbanken, Datentypen und Restriktionen wie \emph{Not Null} definieren.

\begin{figure}[h]
    \lstinputlisting{snippets/basics/graphql-project-type.txt}
    \caption{Project Typdefinition}
    \label{fig:basics:graphql:1}
\end{figure}

\begin{figure}[h]
    \lstinputlisting{snippets/basics/graphql-projects-language-enum.txt}
    \caption{Enum mit Ländercodes}
    \label{fig:basics:graphql:2}
\end{figure}

Die aufgeführten Codefragmente definieren einen Typen Project, mit 2 Feldern und ein Enum mit allen bereitgestellten Sprachen.

\begin{itemize}
    \item \emph{id}: hat den von GraphQL vorgegebenen Typen ID, der als eindeutiger String gewertet wird und nicht dazu gedacht ist vom Menschen "lesbar" zu sein.
    zusätzlich wurde mit "!" festgelegt, dass dieses Feld nicht Null sein darf.
    \item \emph{name}: besitzt den Typen String, der ebenfalls nicht den Wert Null annehmen kann. Zusätzlich wurde dem Feld ein Argument "language" zugeteilt,
    welches den selbst definierten Datentypen LanguageEnum besitzt, mit dem Defaultwert DE.
\end{itemize}

Wie schon erwähnt lassen sich zu Feldern Funktionen definieren die als Resolver betitelt werden.
Für das Feld name ließe sich ein Resolver definieren, der Logik beinhalten könnte um den String, je nach dem welche Sprache als Argument übergeben wurde,
in andere Sprachen zu übersetzen.
Damit ein Datentyp abgefragt werden kann müssen Queries zu den Datentypen definiert werden.

\begin{figure}[h]
    \lstinputlisting{snippets/basics/graphql-projects-query-type.txt}
    \caption{GraphQL Query Typdefinition}
    \label{fig:basics:graphql:3}
\end{figure}

Die Query Typen gehören zum Typsystem von Graphql. Es wird in diesem Fall angegeben, dass es eine Query gibt, die mit dem Bezeichner projects
ein Array vom Typ Project erwartet. Zusätzlich wurde angegeben das ein Project und die Liste nicht Null sein darf.
Es wird also mindestens eine Leeres Array erwartet, aber keinesfalls Null oder ein Array das mit Null Werten gefüllt ist~\cite{graphql}.
Jetzt kann dem Client die Freiheit gewährt werden eigene Abfragen zu formulieren für genau den Datensatz der benötigt wird.
Zudem lässt sich anhand der gestellten Abfrage die Struktur der erhaltenen Antwort festlegen. Dies könnte wie folgt aussehen.

\begin{figure}[h]
    \lstinputlisting{snippets/basics/graphql-projects-request.txt}
    \caption{GraphQL Projects Query}
    \label{fig:basics:graphql:4}
\end{figure}

Der oben aufgeführte Code verkörpert eine GraphQL Query mit dem Namen Projects, die für alle vorhandenen Projekte die Felder id und name
zurück gibt. Nachdem eine GraphQL Query gegen das Typsystem validiert wurde wird sie von dem GraphQL Server ausgeführt und
ein Ergebnis, typischerweise in Form von JSON, zurück gegeben, das die Form und Struktur der Anfrage spiegelt.

\begin{figure}[h]
    \lstinputlisting{snippets/basics/graphql-projects-response.txt}
    \caption{Antwort auf GraphQL Projects Query}
    \label{fig:basics:graphql:5}
\end{figure}

Auf der obersten Ebene eines GraphQL Servers befindet sich ein Typ, der alle möglichen Einstiegspunkte in die GraphQL API repräsentiert.
Dies könnte zum Beispiel der bereits definierte Query-Typ \emph{projects} sein.
Damit der GraphQL Server eine Anfrage an eine an den Server gebundene Datenbank schicken kann wird die zum Query-Typen definierte
Resolver Funktion ausgeführt~\cite{graphql-execution}. Innerhalb dieser Resolver Funktion ist der Zugriff auf das Dateisystem festgelegt, sodass
man neben Datenbanken auch andere Speicherengines oder gar Dateien als Speichermedium nutzen könnte.
Hierzu später noch mehr.

Eine andere Möglichkeit die bereits umrissen wurde wäre die in Kapitel 1.1 vorgestellten Inhalte einer REST API.
Diese setzt voraus, das der Zugriff auf persistent gespeicherte Daten ausschließlich an den Server gekoppelt ist - oftmals in Form einer Datenbank.
Datenzugriffe, die vom Client angestoßen werden, werden über einen festgelegte Menge an vordefinierten Datenbank Transaktionen auf dem Server bereitgestellt.
Jede dieser unterschiedlichen Transaktionen kann über eine Anfrage an den Server ausgelöst werden.


\begin{figure}[h]
    \lstinputlisting{snippets/basics/graphql-rest-transactions.txt}
    \caption{Liste von Routen die auf Controllerfunktionen zeigen}
    \label{fig:basics:graphql:6}
\end{figure}

Die in Abbildung 1 aufgeführte Liste gibt zu jeder Transaktion an über welche Route sie aufgerufen werden kann.
Je größer eine Anwendung wird, desto größer wird der Datenbestand und die Menge an Transaktionen die vordefiniert werden muss.
Für jeden Datensatz der an den Client ausgeliefert werden soll muss also solch ein Eintrag vorgenommen werden und die dazugehörige Transaktion entwickelt werden.
Da bietet GraphQL eine deutlich flexiblere Lösung.


%Nutzung einer statischen Schnittstelle zu einer sich ändernden Implementierung
%https://graphql.org/
%Serverseitigen Rendern arbeiten mit SQL
%Clientseitiges Rendern kein SQL möglich -> Begründung
%Graphql als Lösung für dieses Mismatch/Problem
%Alternative wäre REST API mit 1 Route pro Query

\section{Ausgewählte Details des Typescript Typsystems}
% Definition eines Schemas mit Typescript Interfaces, Bsp. Project Tabelle
% pick operator / exclude operator

\section{JSON Schema}
\label{sec:basics:jsonschema}
Ziel dieses Kapitels ist es anhand eines Beispiels kurz zu erläutern, wobei es sich bei JSON Schema handelt und wie man es nutzen kann.
JSON-Schema ist ein Vokabular, mit dem JSON-Dokumente  annotiert und validiert werden können~\cite{json-schema}.
Es wird genutzt zur Überprüfung, ob JSON Objekte die im JSON-Schema beschriebene Struktur einhalten.
Nehmen wir an wir möchten den in Kapitel GraphQL erstellten Typen Project mit verschiedenen Attributen erweitern.
Eine JSON Instanz soll mindestens folgende Attribute beinhalten, wobei die Angabe, ob es sich bei dem Entwickler
um einen stolzen Vater handelt optional ist.

\begin{figure}[h]
    \lstinputlisting{snippets/JSON-schema-project-object.txt}
    \caption{Ein Projekt als JSON Objekt}
    \label{fig:basics:jsonschema:1}
\end{figure}

Das passendes Schema dazu sieht folgendermaßen aus.

\begin{figure}[h]
    \lstinputlisting{snippets/JSON-schema-project-schema.txt}
    \caption{JSON Schema zu Projekt Objekt}
    \label{fig:basics:jsonschema:2}
\end{figure}

Neben den hier verwendeten Schlüsselwörtern gibt es noch eine Vielzahl Weiterer, die es unter anderem erlauben Einschränkungen, Abhängigkeiten,
Muster in Form von Regulären Ausdrücken oder die maximale oder minimale Anzahl an zu einem Objekt gehörenden Attributen festzulegen.
Die hier verwendeten Schlüsselwörter haben folgende Bedeutung.

\begin{itemize}
    \item \emph{\$schema}: Besagt, dass dieses Schema nach einem bestimmten Entwurf des Standards geschrieben ist, in erster Linie zur Versionskontrolle.
    \item \emph{title/description}: Haben nur beschreibenden Charakter.
    \item \emph{type}: Schlüsselwort für die Typüberprüfung definiert die erste Beschränkung für die JSON-Daten, und in diesem Fall muss es sich um ein JSON-Objekt handeln.
    \item \emph{properties}: Ist für die Validierung von Attributen eines Objekts.
    \item \emph{required}: Da das Schlüsselwort ein Array von Strings beinhaltet, können bei Bedarf mehrere Attribute angeben werden, die erwartet werden.
\end{itemize}

Die händische Erstellung solcher JSON Schema kann bei einer Vielzahl von Typen schnell lästig werden.
Um dem Problem entegegen zu wirken lassen sich aus Typescript Interfaces passende JSON Schema Dateien generieren.
Der Vorteil daraus ist, dass sich clientseitig definierte Datentypen durch die Generierung serverseitig validieren lassen.
Denn für die meisten gängigen Programmiersprachen sind JSON Schema Validatoren entwickelt worden, somit ist es unabhängig welche Programmiersprache der Server nutzt~\cite{json-schema-implementations}.

% kurz halten
% Äquivalenz: typescript Interface und JSON.schema

\section{Postgres jsonb und hstore Typen}
Gegenstand dieses Kapitels ist es zwei Datentypen des Datenbanksystems PostgreSQL näher zu erläutern und miteinander zu vergleichen.
PostgreSQL ist ein objektrelationales Datenbanksystem mit über 30 Jahren aktiver Entwicklung,
das sich einen guten Ruf für Zuverlässigkeit, Robustheit der Funktionen und Leistung erworben hat~\cite{postgresql}.
Im Laufe der Zeit hat Postgresql Unterstützung für JSON-Daten in Form des jsonb und des hstore Datentyps hinzugefügt,
die üblicherweise in NoSQL-Systemen gespeichert werden.
Hstore differenziert sich von jsonb indem es nur eine Ebene von Schlüssel-Werte Paaren, ohne weitere Verschachtelung zulässt und
diese als String abspeichert.
Im Gegensatz dazu können jsonb Datensätze beliebig tief verschachtelt werden und
darüber hinaus werden sie in einem dekomprimierten Binärformat gespeichert, wodurch die Eingabe aufgrund des zusätzlichen Konvertierungs-Overheads etwas langsamer,
die Verarbeitung jedoch erheblich schneller ist, da kein Reparsen erforderlich ist~\cite{postgresql-json}.
Ansonten haben beide Typen in vielen Dingen die gleiche verhaltensweisen, wie bei der Eingabe doppelter Schlüssel, wird nur der letzte Wert beibehalten.
Zudem wurden für beide Datentypen eine beachtliche Menge an Operationen und Funktionen bereitgestellt, die es möglich machen auf SQL Ebene ein hstore oder jsonb Datensatz,
fast wie ein Hash in Ruby oder ein JSON Objekt in Javascript zu behandeln~\cite{postgresql-hstore}.

% Postgres wird benutzt als Dokumenten Datenbank in bezug auf jsonb und hstore

\chapter{Anforderungsanalyse}
\section{Aktuelles System}

Marcus Riemer hat im Rahmen seiner Master-Thesis an der Fachhochschule Wedel die Lehr-Entwicklungsumgebung BlattWerkzeug entwickelt,
die sich an Kinder und Jugendliche richtet. Mit BlattWerkzeug lassen sich, gestützt durch Drag \& Drop-Edi\-toren,
für beliebige SQLite-Datenbanken Abfragen formulieren und Oberflächen entwickeln~\cite[2]{riemer2016}.
Seit dem Abschluss der Master-Thesis wird BlattWerkzeug im Rahmen eines Promotionsvorhabens weiterentwickelt.

%Server:
Der Server ist auf Basis von Ruby mit Rails gebaut. Er dient hauptsächlich der Speicherung und Auslieferung von Daten.
Kommuniziert wird über eine REST-artige JSON-Schnittstelle~\cite[94]{riemer2016}.
%Die für diese Arbeit entwickelte Software baut jedoch lediglich auf dem Client von BlattWerkzeug auf und hat mit der serverseitigen Anwendung keine direkten Berührungspunkte.

%Client:
Der Client wurde als eine Single-Page Application mit rein clientseitiger Visualisierung aufgebaut,
die lediglich für den Zugriff auf serverseitige Resourcen  (Datenbank, gespeicherte Ressourcen,gerenderte Seiten) Roundtrips zum Server nutzt~\cite[94-95]{riemer2016}.
Programmiert wurde sie 2016~\cite[1]{riemer2016} auf Basis von Angular 2 in TypeScript, der damalig neusten Angular Version.
Zum aktuellen Zeitpunkt wird allerdings auf die Angular Version 9.1.0 gesetzt.

%Datenbanksystem

Für die Wahl des einzusetzenden Datenbanksystems wurde sich beim Entwicklungsstart, auf Grund der Kriterien "Kostenlose Verfügbarkeit",
"Einfacher Betrieb", "Einfache Backups", "Tools zur Modellierung" und "Externe Tools zur Entwicklung von SQL-Abfragen"
für eine SQLite Datenbank entschieden~\cite[99-100]{riemer2016}. Im November 2017 ist dann der Grundstein gelegt worden,
um den Server mit einer PostgreSQL Datenbank zu verbinden~\cite{riemerPostgresCommit}, da diese es unter anderem ermöglicht JSON Objekte direkt zu speichern,
ohne diese in Text Datentypen konvertieren zu müssen.
\section{Praxisbeispiel}

\subsection{1. Anlegen des Typescript Interfaces}

\begin{lstlisting}
export interface CodeResourceDescription extends ProjectResourceDescription {
 // The tree that describes the code of this resource.
 ast?: NodeDescription;

 // The actual programming language this resource uses.
 programmingLanguageId: string;

 // The block language this resource uses
 blockLanguageId: string;
}

export interface ProjectResourceDescription
extends IdentifiableResourceDescription {
 // The user-chosen name of this resource. This property is free to change.
 name: string;

 // Date & time this resource was created
 createdAt?: string;

 // Date & time this resource was updated the last time
 updatedAt?: string;
}
\end{lstlisting}
Bsp. CodeResource
List Interface/Response Interface
Dokument Interface
\subsection{2. Generierung der JSON Schema Definitionen}
\begin{lstlisting}
JSON_SCHEMA_FILES = CodeResourceDescription.json

define CONVERT_COMMAND
 @echo "Creating $(notdir $(basename $@)).json"
 $(TYPESCRIPT_JSON_SCHEMA_BIN) --no-type-check --path $^ --type $(notdir $(basename $@)) > "$@.tmp"
 sed -i -- 's/</_/g' "$@.tmp"
 sed -i -- 's/>/_/g' "$@.tmp"
 mv "$@.tmp" "$@"
endef

CodeResourceDescription.json : $(SRC_PATH)/shared/syntaxtree/coderesource.description.ts
$(CONVERT_COMMAND)
\end{lstlisting}

Makefile
\subsection{3. Anlegen des Models in Rails}

\begin{lstlisting}
class CreateCodeResources < ActiveRecord::Migration[5.1]
 def change
  create_table :code_resources, id: :uuid do |t|
  t.string :name, null: false
  t.json :ast, null: true
  t.references :project, type: :uuid

  t.timestamps
  end
 end
end
\end{lstlisting}

\begin{lstlisting}
class CodeResource < ApplicationRecord
 # Each resource belongs to a single project ...
 belongs_to :project
 # ... uses exactly one block language ...
 belongs_to :block_language
 # ... and compiles to exactly one programming language.
 belongs_to :programming_language

 # May be the basis for generated grammars
 has_many :grammars, foreign_key: 'generated_from_id', class_name: 'Grammar'
end
\end{lstlisting}
Datenbankmigration
\subsection{4. Anlegen eines Controllers in Rails}
\begin{lstlisting}
resources :code_resources, only: [:create, :update, :destroy], param: "code_resource_id"
post 'code_resources/:code_resource_id/clone', controller:  'code_resources', action: 'clone'
\end{lstlisting}
\begin{lstlisting}
class CodeResourcesController < ApplicationController

 include JsonSchemaHelper

 # All available code resources for a certain programming language
 def index_by_programming_language
  render json: CodeResource
  .list_by_programming_language(params[:programming_language_id])
 end

 # Create a new resource that is part of a specific project
 def create
  project_id = params[:project_id]
  proj = Project.find_by_slug_or_id! project_id

  res = proj.code_resources.new(code_resource_create_params)
  if res.save
   render :json => res.to_full_api_response, :status => 200
  else
   render :json => { 'errors' => res.errors }, :status => 400
  end
 end
end
 \end{lstlisting}
Für jede Sicht (z.B. Admin/Frontend) eine Route und Controller Funktion.
\subsection{5. DataServices auf dem Client}
\subsection{6. Komponenten auf dem Client}
template
\subsection{7. Neue Sicht}
1. + 2. + 4.(Route + Funktion) + 5. + 6.
Graphql: 5. (Wird generiert) + 6.
\subsection{8. Automatische Generierung von JSON Schema Definitionen}
Anhand von Beispiel: Übersicht über alle

\section{Anforderungen}

\subsection{Mehrsprachigkeit}
Felder in mehreren Sprachen

\subsection{Darstellungsvielfalt}
Nutzerbereich:
Kacheldarstellung auf der Landingpage benötigt weniger Informationen als geliefert werden.
Adminbereich:
Tabellen Übersicht benötigt weniger Daten. Editierung benötigt alle Daten.
Mehrere Requests für einen View

\subsection{End-to-end Typsicherheit}
Erfordert applikationsübergreifende Typdefinitionen.
JSON Schema Validator für Datenbankfelder:
/models/json schema validator
JSON Schema Validator für Requests:
grammars controller update
JSON Schema Validator für Responses:
Rspec
JSON Schema Erzeugung aus Typescript Interfaces:
Aktuell werden Clientseitig JSON Schema Dateien mithilfe von Typescript Interfaces und einem ellenlangen Makefile generiert.

\section{Vorteile des bisherigen Ansatzes}
\section{Nachteile des bisherigen Ansatzes}
\subsection{Auswahl von Attributen}
\subsection{Request und Response Typen}
\subsection{JSON Schema Generierung per Makefile}
Ein Interface pro Anfrage und Antwort erstellen. Pro Interface Eintrag in Makefile.

\section{Typsicherheit}
Typsicherheit muss auf dem Client, wie auf dem Server und in der Datenbank gewährleistet sein. Schreibt ein Programmierer einen neuen Request an den Server,
muss zur Kompilierung auffallen, sollte dieser nach Datenfeldern fragen, die es nicht gibt.

\section{Typdefinition - Server}
Typschema Definition.

\subsection{Datenbankschema}
Muss mit dem Schema übereinstimmen. Möglichkeit der Generierung höchstwahrscheinlich nicht gegeben.
\subsection{JSON Blob Validierung}
Hierbei werden CLientseitige Typdefinitionen benötigt. Möglicher einbau in das serverseitige Schema?

\section{Typdefinition - Client}
\subsection{Codegenerierung}
In diesem Kapitel möchte ich darauf eingehen, dass die Generierung von Clientseitigen Typescript Interfaces z.B. eine Anforderung darstellt, 
da es sich andernfalls kaum vom derzeitigen Lösungsansatz unterscheiden wird. 


\section{Synchronisation der Typdefinitionen}
Zu jedem Zeitpunkt müssen alle Datentypen, ob Server, Client oder Datenbank synchron zu einander sein oder per resolvern umgewandelt werden.

\section{Darstellungsflexibilität}
Nicht mehr Daten als benötigt.
\subsection{Pagination}
Auslieferung von reduzierter Mengen an Daten.
\subsection{Mehrsprachigkeit}

\section{Performance}
Nur ein Request pro Seitenaufruf. Bsp news overview. Effiziente Datenbankqueries.

\section{Skalierbarkeit}

\section{Sonderanforderungen}
\subsection{Schlüsselkonvention - Camelcase/Snakecase}
Angular Client zu Ruby Server kämpfen mit verschiedenen Konvetionen.
\subsection{Mehrsprachigkeit}
Mehrere Sprachen müssen abbildbar sein und in Datenbank gespeichert werden.
\section{Balanced Scorecard Kriterien}
balanced Scoreboard gewichtung der kriterien und formulierung
\chapter{Evaluation von Server Roundtrip Verfahren}

\section{Fast JSON API}
\subsection{Graphiti}
https://www.graphiti.dev/guides/
\subsection{JSON API Scorecard}
\section{GraphQL}
\subsection{Schema-first}
GraphQL Schema in SDL geschrieben. Resolvers für übersetzung zu anderen sprachen etc.
\subsection{Modularisierung}
feature brands?
Eine Datei pro Typ?
Eine große schema Datei?
\subsection{Codeverdoppelung}
Bei der Pagination.
\subsection{Code-first}
Nutzung von gapqhl-ruby
https://github.com/rmosolgo/graphql-ruby
\subsection{GraphQL Scorecard}
\section{Optimierung der bestehenden Lösung - make or buy}
Narrow-Funktion um nur einen Request pro Seitenaufruf ermöglichen zu können. JSON Api Konzept wird dabei teilweise genutzt.
\section{Zusätzliche Verfahren}
\subsection{Deepr}
Gibt es nur in Javascript.
https://github.com/deeprjs/deepr
\subsection{Deepr Scorecard}
\section{Balanced Scorecard}
\chapter{Implementierung}

\chapter{Fazit}
\section{Erreichte Ziele}
\section{Nicht erreichte Ziele}
\section{Ausblick}
Server Round Trip mit TCP messen nicht mit ICMP. Tracer middleware
