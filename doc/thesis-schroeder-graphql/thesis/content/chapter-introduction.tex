%! Author = Yannick Schröder
%! Date = 13.05.20

%************************************************
% Grundlagen
%************************************************
\chapter{Einleitung}
\label{sec:introduction}

Ziel dieser Arbeit ist die Evaluierung von Verfahren, welche eine sichere, effiziente und leichte Nutzung der Kommunikationsschnittstellen 
zwischen Client, Server und Datenbank ermöglichen sollen und wenn möglich die Integration eines dieser Verfahren
in die von Marcus Riemer entwickelte Lehr-Entwicklungsumgebung BlattWerkzeug (siehe~\fullref{sec:basics}),
In den nächsten Kapiteln sind die Probleme des derzeitigen Verfahrens und die Anforderungen an die Nutzung der Kommunikationsschnittstellen näher beschrieben.
%Das im Rahmen dieser Arbeit zu entwickelnde Tool soll sich in BlattWerkzeug integrieren und die aktuellen Kommunikationsschnittstellen wenn möglich ersetzen.

%************************************************
% Status Quo
%************************************************
\chapter{Grundlagen}
\label{sec:basics}
Das wesentliche Motiv bei der Nutzung des Internets ist die In\-for\-ma\-tions\-auf\-nah\-me~\cite{statista-1}\cite{ard-zdf}.
Informationen werden auf unzähligen Webapplikationen bereitgestellt, die jeder mit einem Internetzugang einsehen kann,
solange der Zugriff auf die Informationen nicht sonderlich geschützt wird.

Um persistente und sensible Daten gesichert und nicht für Jedermann zugreifbar lagern zu können, werden sie \emph{serverseitig} gehalten.
Möchte man diese Daten zusätzlich filtern, sortieren oder mehrere Datensätze miteinander verknüpfen, wird eine Datenbank benötigt.
Eine Datei, in der die Daten abgelegt werden, wäre auch eine Option, allerdings müsste man alle Methoden zum Filtern, Sortieren und Verknüpfen
selber implementieren.

Die in einer Datenbank gespeicherten Informationen sind also aus Nutzersicht nur über eine Anfrage an den Sever abrufbar.
Somit ist der Server das Bindeglied zwischen einem Client und der Datenbank und kümmert sich um Aufgaben wie Authentifizierung des Nutzers
und Überprüfung der Authorisierung bezüglich der angefragten Daten, aber auch um die Zusammensetzung und Ausführung von Datenbankabfragen.
Daraus geht hervor, dass ein Client nur begrenzten Zugriff bekommt, da die Ausführung von vordefinierten Funktionen, die Anfragen an die Datenbank beinhalten,
lediglich angefragt werden kann. Werden die vordefinierten Funktionen den Bedarf an Informationen nicht gerecht, müssen neue Funktionen entwickelt
oder mithilfe von mehreren Anfragen die Daten zusammengesammelt werden.

Dieser Entwicklungsaufwand könnte verringert werden, indem der Client mehr Flexibilität, Verantwortung und Effizienz besitzen würde,
z.B. durch eine direkte Anbindung an die Datenbank.
Er könnte exakt die benötigten Daten, mit nur einer Anfrage direkt und effizient aus der Datenbank auslesen.
Jedoch würde dieser Ansatz viele Gefahren mit sich bringen. Ein Client der direkten Datenbankzugriff erlangt,
könnte unerwünschte Transaktionen in der Datenbank ausführen, wodurch der erwartete Datenbestand geändert,
Einträge gar gelöscht oder sensible Daten anderer Nutzer abgefragt werden könnten. Also sollten Zugriffsbeschränkungen erteilt werden, die
auf der Datenbankschicht realisiert werden, da clientseitiger Code nach Belieben vom Nutzer eingesehen und verändert werden kann.
Hinzu kommen weitere Herausforderungen, wenn die Verbindung zur Datenbank veröffentlicht wird,
wie zum Beispiel das Schützen vor zu exzessiver Nutzung oder das Ausnutzen von bekannten Sicherheitslücken bei nicht aktuellsten Versionen~\cite{postgresql-security}.
Alles in allem ist das ein Verfahren, von dem dringend abgeraten wird, da es in den wenigsten Fällen nutzbringend und sicher gehandhabt werden kann~\cite{client-to-database}.

Im Folgenden werden diese Probleme anhand von grundlegenden Inhalten, die aktuell Gegenstand des von Marcus Riemers entwickelten Systems~\cite{riemer2016} sind,
wieder aufgegriffen und bei Erläuterungen bzw. Code-Beispielen als bekannt vorausgesetzt.
Dazu gehören die Unterkapitel \fullref{sec:basics:restapi}, \fullref{sec:basics:typescript}, \fullref{sec:basics:jsonschema} und \fullref{sec:basics:postgres}.
Diese müssen für die Schaffung und Umsetzung von Verbesserungen grundlegend verstanden werden.
Bei dem Kapitel \fullref{sec:basics:graphql} handelt es sich um eine Abfragesprache und Laufzeitumgebung,
für die im Laufe der Arbeit evaluiert wird, ob sie gewinnbringend in das bestehende System migriert werden und Teile ersetzen kann.

%Nicht spezifisch auf Blattwerzeuge werden!! Kleines Beispiel ist erlaubt (Begriff Blattwerzeug wird nicht erwähnt).
\section{REST API}
\label{sec:basics:restapi}
Der Begriff Representational State Transfer (abgekürzt REST, seltener auch ReST) wurde erstmalig in der Dissertation "Architectural Styles and the Design of
Network-based Software Architectures" von Roy Thomas Fielding im Jahr 2000 geprägt~\cite{fielding-dissertation}.
Er beschreibt REST als einen Architekturstil für verteilte Systeme, welcher in eine einheitliche Schnittstelle für Kommunikation mündet.
Dieser Architekturstil oder auch Programmierparadigma wird durch verschiedene Software-Engineering-Prinzipien und Beschränkungen definiert.
Im Folgenden werden die Prinzipien von REST näher erläutert.

\subsection{Client-Server-Modell}
Der Ausgangspunkt des Client-Server-Modells ist eine strikte Trennung der Benutzeroberfläche von der Datenhaltung/-verwertung.
Das bedeutet wiederum, dass kein HTML, CSS und Javascript vom Server an den Client geschickt wird, sondern ausschließlich Datensätze
meist in Form von XML oder JSON, die clientseitig in die Benutzeroberfläche eingebaut werden.
Dadurch verbessert sich die Portabilität der Benutzeroberfläche in Bezug auf die Anbindung an verschiedene Datenhaltungs/-verwertungs-Systeme,
also die Wiederverwendbarkeit und die Skalierbarkeit aufgrund der Vereinfachung der Serverkomponenten.

\subsection{Zustandslosigkeit}
Zustandslosigkeit ist eine Beschränkung in Bezug auf die Kommunikation zwischen Server und Client.
Anfragen vom Client müssen alle Informationen beinhalten um diese interpretieren zu können.
Insbesondere werden Anfragen ohne Bezug zu früheren Anfragen behandelt und keine Sitzungsinformationen -
wie Authentifizierungs- und Authorisierungsinformationen - ausgetauscht bzw. verwaltet.
Diese befinden sich ausschließlich auf dem Client und müssen bei Anforderung von geschützten Daten der Anfrage beigefügt werden.

Vorteile aus dieser Beschränkung sind, dass Anfragen unabhängig voneinander betrachtet werden können
und somit z.B. von mehreren Maschinen parallel ausgeführt werden können, da jede Anfrage für sich eine vollständige Anforderung an den Server beschreibt.
Zudem kann einfacher auf den Misserfolg einer Anfrage reagiert werden, als auf eine erfolglose Kette von zusammenhängenden Anfragen
und es ist nicht vonnöten Zwischenzustände bzw. Status zu speichern, welche die Ressourcenauslastung erhöhen würde.
Dies kann jedoch zu einer verringerten Netzwerkleistung führen aufgrund von Zusatzinformationen,
die sich bei mehreren verschiedenen Anfragen wiederholen und erneut mit gesendet werden müssen.

\subsection{Cache}
In Hinblick auf das Verbessern der Netzwerkleistung wurde ein Cache als Einschränkung hinzugefügt.
Diese Einschränkung setzt voraus, dass Daten aus einer Antwort vom Server implizit oder explizit als cachefähig oder nicht cachefähig gekennzeichnet werden.
Werden Daten in einer Antwort auf eine Anfrage als cachefähig gekennzeichnet, kann der Client diese Information speichern und erhält das Recht diese
bei einer späteren gleichwertigen Anfrage wiederzuverwenden.
Somit können Anfragen effizienter behandelt bzw. ganz durch eine direkt aus dem Cache geladene Antwort ersetzt werden.

\subsection{Einheitliche Schnittstelle}
Ein zentrales Merkmal von REST ist die einheitliche und vom Dienst entkoppelte Schnittstelle.
Auf jede Ressource muss über einen einheitlichen Satz an URLs, hinter denen sich Transaktionen zum Erstellen, Lesen, Aktualisieren
und zum Löschen (CRUD) verbergen, zugegriffen werden können.

Durch eine einheitliche Komponentenschnittstelle wird die Sichtbarkeit der einzelnen Interaktionen erhöht.
Dies bedeutet, dass es für jede Ressource eine Menge fest definierter Interaktionen gibt, die sich in ihrer Struktur nur durch den Namen der
Ressource und ihre Fremdbeziehungen unterscheiden.

\begin{table}[h]
    \begin{tabular}{|p{0.11\textwidth}|p{0.08\textwidth}|p{0.12\textwidth}|p{0.2\textwidth}|p{0.35\textwidth}|}
        \hline
        \textbf{CRUD\newline  Operation} & \textbf{SQL} & \textbf{HTTP} & \textbf{URL} & \textbf{Bedeutung} \\ \hline
        Create & \inlinec{INSERT} & \inlinec{POST} & \inlinec{/projects} & Erstellen eines Projekts \\ \hline
        Read & \inlinec{SELECT} & \inlinec{GET} & \inlinec{/projects} & Abrufen aller Projekte \\ \hline
        Read & \inlinec{SELECT} & \inlinec{GET} & \inlinec{/projects/:id} & Abrufen eines Projekts \\ \hline
        Update & \inlinec{UPDATE} & \inlinec{PATCH/PUT} & \inlinec{/projects/:id} & Aktualisieren eines Projekts \\ \hline
        Delete & \inlinec{DELETE} &\inlinec{DELETE} & \inlinec{/projects/:id} & Löschen eines Projekts \\ \hline
        Read & \inlinec{SELECT} &\inlinec{GET} & \inlinec{/projects/:id/- developer} & Abrufen des Entwicklers eines Projekts \\ \hline
    \end{tabular}
    \vspace{5pt}
    \caption{Einheitliche Schnittstellen}
    \label{tbl:basics:crud}
\end{table}

Das hat zur Folge, dass anwendungsspezifische Daten in einer standardisierten Form übertragen werden müssen,
wodurch die Effizienz der Datenübertragung Mängel aufwerfen kann.

\subsection{Layered System}
Der Layered System Software-Architekturstil beschreibt das Prinzip eines hierachisch in Schichten aufgebauten Systems.
Jede Komponente kann ausschließlich Schichten "sehen", mit denen sie interagiert.
Eine Anwendung kann dadurch ihre Anforderungen auf mehrere Schichten verteilen, wie zum Beispiel bei einer Anwendung, die ihre API auf Server A anbietet,
die Daten auf Server B lagert und einen Authentifizierungsdienst von Server C nutzt.
Nachteile dieser Einschränkung spiegeln sich in gestiegener Komplexität der Gesamtarchitektur und kommunikativem Overhead wieder.

Desweiteren gibt es noch eine optionale Einschränkung \emph{Code-On-Demand}, welche die Client-Funktionalität durch Herunterladen und Ausführen von Code in
Form von Applets oder Skripten erweitert. Diese wird im Rahmen der Arbeit nicht genutzt und deshalb nur am Rande erwähnt.
%Als Entwickler einer Anwendung stellt Modularität ein von Beginn an bedachtes Kalkül dar.

\section{GraphQL}
\label{sec:basics:graphql}
%Nutzung einer statischen Schnittstelle zu einer sich ändernden Implementierung
GraphQL dient als Lösung für die in Kapitel \fullref{sec:basics} aufgeführten Probleme, besonders in Bezug auf Flexibilität, Verantwortung und Effizienz~\cite{graphql-scalablepath}.
Es handelt sich um eine Abfragesprache für APIs und eine Laufzeitumgebnung,
zum Ausführen dieser Abfragen und Wiedergeben von Daten unter Verwendung eines von für die Daten definierten Typensystems.
Es ist an keinerlei Datenbanksysteme gebunden und lässt sich gut mit vorhandenen Code und Daten verbinden.

Ein GraphQL Service entsteht durch das Definieren von Typen, vergleichbar mit Datenbanktabellen. Zu jedem Feld eines Typs lassen sich - geanuso wie bei Datenbanken -
Datentypen und Restriktionen wie \emph{NOT NULL} definieren.

\begin{figure}[h]
    \lstinputlisting{snippets/basics/graphql-project-type.txt}
    \caption{Project Typdefinition}
    \label{fig:basics:graphql:1}
\end{figure}

Das aufgeführte Codefragment~\fullref{fig:basics:graphql:1} definiert einen Typen \emph{Project} mit zwei Feldern, welcher ein Programmierprojekt darstellen soll.
\begin{itemize}
    \item \emph{id}: hat den von GraphQL vorgegebenen Typen ID, der als eindeutiger String gewertet wird und nicht dazu gedacht ist vom Menschen "lesbar" zu sein.
    Zusätzlich wurde mit "!" festgelegt, dass dieses Feld nicht Null sein darf.
    \item \emph{public}: besitzt den Typen Boolean, der ebenfalls nicht den Wert Null annehmen kann.
    Es gibt an, ob das Projekt bereits veröffentlicht und für jeden zugreifbar gemacht wurde.
\end{itemize}

Im Gegensatz zu einem Datenbank-Schema ermöglicht das Typsystem von GraphQL zu jedem Typen Argumente zu definieren,
die wiederum einer Funktion (Resolver) übergeben werden können,
die aufgerufen wird, wenn das Feld im Kontext einer Query aufgelöst werden soll~\cite{graphql-resolver}.
Erweitern wir für ein Beispiel unseren Typen um ein Feld:

\begin{figure}[h]
    \lstinputlisting{snippets/basics/graphql-project-full-type.txt}
    \caption{Erweiterung der Typdefinition von Project}
    \label{fig:basics:graphql:3}
\end{figure}

\begin{figure}[h]
    \lstinputlisting{snippets/basics/graphql-projects-name-resolver.txt}
    \caption{Resolver des Feldes \emph{name}}
    \label{fig:basics:graphql:4}
\end{figure}

\begin{figure}[h]
    \lstinputlisting{snippets/basics/graphql-projects-language-enum.txt}
    \caption{Enum mit Ländercodes}
    \label{fig:basics:graphql:2}
\end{figure}

\begin{itemize}
    \item \emph{name}: besitzt den Typen String, der ebenfalls nicht den Wert Null annehmen kann. Zusätzlich wurde dem Feld ein Argument "language" zugeteilt,
    welches den selbst definierten Datentypen LanguageEnum besitzt mit dem Defaultwert DE.
\end{itemize}

Obendrein wurde für das Feld \emph{name} ein Resolver definiert, der Logik beinhaltet, um den String, je nach dem welche Sprache als Argument übergeben wurde,
in andere Sprachen zu übersetzen.

Damit ein Datentyp abgefragt werden kann, müssen Queries zu den Datentypen definiert werden.

\begin{figure}[h]
    \lstinputlisting{snippets/basics/graphql-projects-query-type.txt}
    \caption{GraphQL Query Typdefinition}
    \label{fig:basics:graphql:5}
\end{figure}

Die Query Typen gehören zum Typsystem von Graphql. Es wird in diesem Fall angegeben, dass es eine Query gibt, die mit dem Bezeichner \emph{projects}
ein Array vom Typ \emph{Project} erwartet. Zusätzlich wurde angegeben, dass ein Projekt und die Liste nicht Null sein dürfen.
Es wird also mindestens eine leeres Array erwartet, aber keinesfalls Null oder ein Array, das mit Null-Werten gefüllt ist~\cite{graphql}.
Jetzt kann dem Client die Freiheit gewährt werden eigene Abfragen für genau den Datensatz der benötigt wird zu formulieren.
Zudem lässt sich anhand der gestellten Abfrage die Struktur der erhaltenen Antwort festlegen. Dies könnte wie folgt aussehen:

\begin{figure}[h]
    \lstinputlisting{snippets/basics/graphql-projects-request.txt}
    \caption{GraphQL Projects Query}
    \label{fig:basics:graphql:6}
\end{figure}

Der aufgeführte Code~\fullref{fig:basics:graphql:6} verkörpert eine GraphQL Query mit dem Namen \emph{Projects}, die für alle vorhandenen Projekte die Felder \emph{id} und \emph{name}
zurückgibt. Nachdem eine GraphQL Query gegen das Typsystem validiert wurde, wird sie von dem GraphQL Server ausgeführt und
ein Ergebnis - typischerweise in Form von JSON - zurückgegeben, das die Form und Struktur der Anfrage spiegelt.

\begin{figure}[h]
    \lstinputlisting{snippets/basics/graphql-projects-response.txt}
    \caption{JSON Antwort auf die Projects Query}
    \label{fig:basics:graphql:7}
\end{figure}

Auf der obersten Ebene eines GraphQL Servers befindet sich ein Typ, der alle möglichen Einstiegspunkte in die GraphQL API repräsentiert.
Dies könnte zum Beispiel der bereits definierte Query-Typ \emph{projects} sein.
Damit der GraphQL Server eine Anfrage an eine an den Server gebundene Datenbank schicken kann, wird die zum Query-Typen definierte
Resolver-Funktion ausgeführt~\cite{graphql-execution}. Innerhalb dieser Resolver-Funktion ist der Zugriff auf das Dateisystem festgelegt, sodass
man neben Datenbanken oder gar Dateien als Speichermedium nutzen könnte. Hierzu später noch mehr.

Eine andere Möglichkeit, die bereits umrissen wurde, wären die in Kapitel~\fullref{sec:basics:restapi} vorgestellten Inhalte einer REST API.
Diese setzt voraus, dass der Zugriff auf persistent gespeicherte Daten ausschließlich an den Server gekoppelt ist - oftmals in Form einer Datenbank.
Datenzugriffe, die vom Client angestoßen werden, werden über eine festgelegte Menge an vordefinierten Transaktionen auf dem Server bereitgestellt.
Jede dieser unterschiedlichen Transaktionen kann über eine Anfrage an den Server ausgelöst werden.

Die in Tabelle~\fullref{tbl:basics:crud} aufgeführte Liste gibt zu jeder Transaktion an, über welche Route sie aufgerufen werden kann.
Je größer eine Anwendung wird, desto größer wird der Datenbestand und damit die Menge an Transaktionen, die vordefiniert werden muss.
Für jeden Datensatz, der an den Client ausgeliefert werden soll, muss also solch ein Eintrag vorgenommen werden und die dazugehörige Transaktion entwickelt werden.

%Nutzung einer statischen Schnittstelle zu einer sich ändernden Implementierung
%https://graphql.org/
%Serverseitigen Rendern arbeiten mit SQL
%Clientseitiges Rendern kein SQL möglich -> Begründung
%Graphql als Lösung für dieses Mismatch/Problem
%Alternative wäre REST API mit 1 Route pro Query

\section{Ausgewählte Details des Typescript Typsystems}
\label{sec:basics:typescript}
TypeScript ist ein typisiertes Superset von Javascript, das zu reinem Javascript kompiliert~\cite{typescript}.
Das heisst, es beinhaltet alle Funktionalitäten von Javascript und wurde darüber hinaus erweitert und verbessert~\cite{superset}.
Dazu gehört das in Typescript eingeführte Typsystem. Selbstverständlich besitzt Javascript ebenfalls Typen, doch kann eine Variable,
auf die ursprünglich eine \emph{number} zugewiesen wurde, auch als \emph{string} enden. Das kann schnell zu unbedachten Seiteneffekten führen.

Was ist also ein Typsystem? Ein Typsystem ist eine Menge von Regeln, die jeder Variable, jedem Ausdruck, jeder Klasse,
jeder Funktion, jedem Objekt oder Modul im System einen Typ zuweist.
Diese Regeln werden zur  Kompilierungszeit (statische Typprüfung) oder zur Laufzeit (dynamische Typprüfung) geprüft,
um Fehler in einem Programm aufzudecken~\cite{typescript-typesystem-medium}.

Der Typescript-Compiler prüft zur Kompilierungszeit alle Variablen und Ausdrücke auf ihren Typen und entfernt anschließend alle Typinformationen
bei der Konvertierung zu Javascript Code~\cite{typescript-github-specification}.
Die im folgenden Beispiel deklarierte Funktion gibt die zweite Hälfte eines übergebenen \emph{strings} zurück.
Der erste Aufruf der Funktion führt zu einem Fehler beim Kompilieren. Es wird also direkt darauf hingewiesen, dass es sich um ein fehlerhaften Code handelt.

\begin{figure}[h]
    \lstinputlisting{snippets/basics/typescript-example.txt}
    \caption{Typescript Funktion mit typisiertem Parameter}
    \label{fig:basics:typescript:1}
\end{figure}

Nach der Kompilierung sind alle Typinformationen entfernt worden, wodurch erst durch einen fehlerhaften Aufruf
ein \emph{TypeError} auftritt.

\begin{figure}[h]
    \lstinputlisting{snippets/basics/typescript-example-compiled.txt}
    \caption{Zu Javascript kompilierte Funktion}
    \label{fig:basics:typescript:2}
\end{figure}

Nehmen wir an, wir möchten den in Kapitel GraphQL~\fullref{sec:basics:graphql} erstellten Typen \emph{Project} nutzen,
um eine Funktion zu schreiben, die einen neuen \emph{Project} Datensatz an den Server schickt. Um diesen Typen clientseitig nutzen zu können,
können wir ein äquivalentes Typescript Interface erstellen oder eines generieren lassen (dazu später mehr).

\begin{figure}[h]
    \lstinputlisting{snippets/basics/typescript-project-interface.txt}
    \caption{Typescript Project Interface}
    \label{fig:basics:typescript:3}
\end{figure}

Wollen wir jetzt einen neuen Datensatz an den Server schicken, können wir das Interface nutzen. Jedoch ist nur der Name des neuen Datensatzes bekannt,
die \emph{id} ist eine \emph{uuid} und wird serverseitig generiert. Also wollen wir die \emph{id} beim clientseitigen Erstellen außen vorlassen.
Dafür bietet Typescript unter einer Vielzahl von Werkzeugen, die allgemeine Typtransformationen ermöglichen~\cite{typescript-utility-types},
\emph{Omit<T,K>}, das alle Attribute von \emph{T} nimmt und anschließend \emph{K} aus den Attributen entfernt.

\begin{figure}[h]
    \lstinputlisting{snippets/basics/typescript-post-project.txt}
    \caption{Transformierter \emph{Project} Typ}
    \label{fig:basics:typescript:4}
\end{figure}

Der Typ \emph{PostProject} beinhaltet also alle Felder von \emph{Project}, allerdings ohne \emph{id}. Das Gegenstück zu \emph{Omit<T,K>} wäre \emph{Pick<T,K>},
welches aus dem Typ \emph{T} nur die Attribute \emph{K} nimmt. Mithilfe dieser Typen lässt sich eine typsichere Methode entwickeln,
um einen neuen Datensatz an den Server schicken zu können.

\begin{figure}[h]
    \lstinputlisting{snippets/basics/typescript-create-project-request.txt}
    \caption{Typen und Methode zum Abschicken eines \emph{Project}-Datensatzes}
    \label{fig:basics:typescript:5}
\end{figure}

Die Methode \inlinec{createProjectRecord} erwartet also ein \inlinec{Project} ohne \inlinec{id} als Parameter und gibt ein \inlinec{ProjectResponse} wieder.
Der Code im Methodenrumpf ist hierbei nur Pseudocode. Der Typ \inlinec{ProjectResponse} beinhaltet neben dem \inlinec{Project} auch ein \inlinec{error} Feld,
welches in dem Kontext angibt, ob ein neuer Datensatz auf dem Server erstellt werden konnte oder nicht.
Desweiteren gibt es noch \inlinec{Exclude<T,U>} wodurch sich von T diejenigen Typen ausschließen lassen,
die U zugeordnet werden können. Gäbe es mehrere \emph{"Response"}-Typen, ließe sich das Feld extrahieren,
über welches auf die Datensätze zugegriffen werden kann (siehe~\fullref{fig:basics:typescript:6})(dazu später mehr).

\begin{figure}[h]
    \lstinputlisting{snippets/basics/typescript-datakey.txt}
    \caption{Exclude zum Exkludieren von Schlüsseln}
    \label{fig:basics:typescript:6}
\end{figure}

% Definition eines Schemas mit Typescript Interfaces, Bsp. Project Tabelle
% pick operator / exclude operator

\section{JSON Schema}
\label{sec:basics:jsonschema}
JSON-Schema ist ein Vokabular, mit dem JSON-Dokumente  annotiert und validiert werden können~\cite{json-schema}.
Es wird zur Überprüfung genutzt, ob JSON Objekte die im JSON-Schema beschriebene Struktur einhalten.

Der Vorgänger von JSON-Schema war das XML-Schema.
XML-Schema erlaubte es, das allgemeine Format eines XML-Dokuments zu definieren,
d.h. welche Elemente erlaubt sind, die Anzahl und Reihenfolge ihres Auftretens, welchen Datentyp sie haben sollen usw.
Seit 2006 gibt es einen neuen Akteur auf dem Gebiet der Datenformate, JavaScript Object Notation (JSON).
Die JSON Daten sind viel kleiner als ihr XML-Gegenstück und ihre Instanzen sind gültige JavaScript-Objekte, was es interessant für Webentwickler macht, da sie beim Laden von
Informationen in asynchronen Webanwendungen über AJAX (Asynchronous JavaScript and XML) keinen separaten Konvertierungsschritt mehr benötigen~\cite{json-schema-xml}.

Nehmen wir an, wir möchten den in Kapitel GraphQL erstellten Typen \emph{Project}~\fullref{fig:basics:graphql:3} mit verschiedenen Attributen erweitern.
Eine JSON Instanz soll mindestens folgende Attribute beinhalten, wobei die Angabe, ob es sich bei dem Entwickler
um einen proudFather handelt, optional ist.

\begin{figure}[h]
    \lstinputlisting{snippets/JSON-schema-project-object.txt}
    \caption{Ein Projekt als JSON Objekt}
    \label{fig:basics:jsonschema:1}
\end{figure}

Das passendes Schema dazu sieht folgendermaßen aus~\fullref{fig:basics:jsonschema:2}.

\begin{figure}[hb!]
    \lstinputlisting{snippets/JSON-schema-project-schema.txt}
    \caption{JSON Schema zu Projekt Objekt}
    \label{fig:basics:jsonschema:2}
\end{figure}

Neben den verwendeten Schlüsselwörtern gibt es noch eine Vielzahl weiterer, die es unter anderem erlauben Einschränkungen, Abhängigkeiten,
Muster in Form von Regulären Ausdrücken oder die maximale oder minimale Anzahl an zu einem Objekt gehörende Attribute festzulegen.
Die hier verwendeten Schlüsselwörter haben folgende Bedeutung:

\begin{itemize}
    \label{basics:jsonschema:items}
    \setlength\itemsep{-1em}
    \item \emph{2: \$schema}: besagt, dass dieses Schema nach einem bestimmten Entwurf des Standards geschrieben ist, in erster Linie zur Versionskontrolle.
    \item \emph{3: title/description}: haben nur beschreibenden Charakter.
    \item \emph{5: type}: Dieses Schlüsselwort für die Typüberprüfung definiert die erste Beschränkung für die JSON-Daten und in diesem Fall muss es sich um ein JSON-Objekt handeln.
    \item \emph{6: properties}: ist für die Validierung von Attributen eines Objekts.
    \item \emph{36: required}: Da dieses Schlüsselwort ein Array von Strings beinhaltet, können bei Bedarf mehrere Attribute angeben werden, die erwartet werden.
\end{itemize}

Nehmen wir an ein Entwickler hat ein fehlerhaftes Projekt wie folgt erstellt~\fullref{fig:basics:jsonschema:3}.

\begin{figure}[hb!]
    \lstinputlisting{snippets/JSON-schema-project-wrong-object.txt}
    \caption{Ein fehlerhaftes Projekt}
    \label{fig:basics:jsonschema:3}
\end{figure}

Es kommt bei der Validierung dieses Objektes zu folgenden Verstößen:

\begin{itemize}
    \setlength\itemsep{-1em}
    \item \emph{name}: ist im \emph{required} Array angegeben und muss somit vorhanden sein.
    \item \emph{createdAt}: Es wurde ein falscher Datentyp angegeben, \emph{string} statt \emph{number}.
    \item \emph{professor}: Dieses Attribut ist nicht im \emph{properties} Objekt angegeben und dadurch fehl am Platz.
\end{itemize}

Die händische Erstellung solcher JSON-Schema kann bei einer Vielzahl von Typen schnell lästig werden.
Um dem Problem entgegen zu wirken lassen sich aus Typescript Interfaces passende JSON-Schema Dateien generieren.
Der Vorteil daran ist, dass sich clientseitig definierte Datentypen durch die Generierung serverseitig validieren lassen;
denn für die meisten gängigen Programmiersprachen sind JSON-Schema Validatoren entwickelt worden.
Somit ist es unabhängig welche Programmiersprache der Server nutzt~\cite{json-schema-implementations}.

% kurz halten
% Äquivalenz: typescript Interface und JSON.schema

\section{Postgres jsonb und hstore Typen}
\label{sec:basics:postgres}
Das PostgreSQL Datenbanksystem kennt über den SQL-Standard hinaus die Datentypen \emph{hstore} und \emph{jsonb} zur Speicherung von JSON Strukturen oder assoziativen Arrays,
die üblicherweise in NoSQL-Systemen gespeichert werden.
Hstore differenziert sich von jsonb, indem es nur eine Ebene von Schlüssel-Werte-Paaren ohne weitere Verschachtelungen zulässt und
diese als String abspeichert.
Im Gegensatz dazu können jsonb Datensätze beliebig tief verschachtelt werden und
darüber hinaus werden sie in einem dekomprimierten Binärformat gespeichert, wodurch die Eingabe aufgrund des zusätzlichen Konvertierungs-Overheads etwas langsamer,
die Verarbeitung jedoch erheblich schneller ist, da kein Reparsen erforderlich ist~\cite{postgresql-json}.
Ansonsten haben beide Typen in vielen Dingen die gleichen Verhaltensweisen. Wie bei der Eingabe doppelter Schlüssel wird nur der letzte Wert beibehalten.
Zudem wurden für beide Datentypen eine beachtliche Menge an Operationen und Funktionen bereitgestellt (siehe Abbildung~\fullref{tbl:basics:hstore-operations}), die es möglich machen,
auf SQL Ebene einen hstore oder jsonb Datensatz fast wie ein Hash in Ruby oder ein JSON-Objekt in Javascript zu behandeln~\cite{postgresql-hstore}.

\begin{table}[h]
    \small
    \begin{tabular}{|p{0.21\textwidth}|p{0.31\textwidth}|p{0.33\textwidth}|p{0.1\textwidth}|}
        \hline
        \textbf{Operator} & \textbf{Beschreibung} & \textbf{Beispiel} & \textbf{Ergebnis}  \\ \hline
        \inlinec{hstore -> text} & liefert Wert für Schlüssel (NULL, wenn nicht vorhanden) & \inlinec{'a=>x, b=>y'::hstore -> 'a'} & \inlinec{x}  \\ \hline
        \inlinec{hstore -> text[]} & liefert Werte für Schlüssel (NULL, wenn nicht vorhanden) & \inlinec{'a=>x, b=>y, c=>z'::hstore -> ARRAY['c','a']} & \inlinec{{"z","x"}}  \\ \hline
        \inlinec{hstore || hstore} & konkateniert hstores & \inlinec{'a=>b, c=>d'::hstore || 'c=>x, d=>q'::hstore} & \inlinec{"a"=>"b", "c"=>"x", "d"=>"q"}  \\ \hline
        \inlinec{hstore ? text} & prüft ob hstore Schlüssel beinhaltet & \inlinec{'a=>1'::hstore ? 'a'} & \inlinec{t}  \\ \hline
        \inlinec{hstore - text} & entfernt Schlüssel des linken Operanden & \inlinec{'a=>1, b=>2, c=>3'::hstore - 'b'::text} & \inlinec{"a"=>"1", "c"=>"3"}  \\ \hline
        \inlinec{hstore - hstore } & entfernt passende Schlüssel/Wert-Paare vom linken Operanden & \inlinec{'a=>1, b=>2, c=>3'::hstore - 'a=>4, b=>2'::hstore} & \inlinec{"a"=>"1", "c"=>"3"}  \\ \hline
    \end{tabular}
    \vspace{5pt}
    \caption{Beispiele für bereitgestellte Hstore Operationen}
    \label{tbl:basics:hstore-operations}
\end{table}

% Postgres wird benutzt als Dokumenten Datenbank in bezug auf jsonb und hstore
\chapter{Anforderungsanalyse}
\label{sec:requirements}

\section{Aktuelles System}
\label{sec:requirements:system}

Marcus Riemer hat im Rahmen seiner Master-Thesis an der Fachhochschule Wedel die Lehr-Entwicklungsumgebung BlattWerkzeug als Webapplikation entwickelt,
die sich an Kinder und Jugendliche richtet. Mit BlattWerkzeug lassen sich, gestützt durch Drag \& Drop-Edi\-toren,
für beliebige SQLite-Datenbanken Abfragen formulieren und Oberflächen entwickeln~\cite[2]{riemer2016}.
Seit dem Abschluss der Master-Thesis wird BlattWerkzeug im Rahmen eines Promotionsvorhabens weiterentwickelt.

%Server:
Der Server dieser Web-App ist auf Basis von Ruby on Rails gebaut. Er dient hauptsächlich der Speicherung und Auslieferung von Daten.
Kommuniziert wird über eine REST-artige JSON-Schnittstelle~\cite[94]{riemer2016}.

%Client:
Der Client wurde als eine Single-Page Application mit rein clientseitiger Visualisierung aufgebaut,
die lediglich für den Zugriff auf serverseitige Resourcen  (Datenbank, gespeicherte Ressourcen, gerenderte Seiten) Roundtrips zum Server nutzt~\cite[94-95]{riemer2016}.
Programmiert wurde sie 2016~\cite[1]{riemer2016} auf Basis von Angular 2 in TypeScript, der damalig neusten Angular Version.
Zum aktuellen Zeitpunkt wird allerdings auf die Angular Version 9.1.0 gesetzt.

%Datenbanksystem
Für die Wahl des einzusetzenden Datenbanksystems wurde sich beim Entwicklungsstart, auf Grund der Kriterien "Kostenlose Verfügbarkeit",
"Einfacher Betrieb", "Einfache Backups", "Tools zur Modellierung" und "Externe Tools zur Entwicklung von SQL-Abfragen"
für eine SQLite Datenbank entschieden~\cite[99-100]{riemer2016}. Im November 2017 ist dann der Grundstein gelegt worden,
um den Server mit einer PostgreSQL Datenbank zu verbinden~\cite{riemerPostgresCommit}, da diese es unter anderem ermöglicht JSON Objekte direkt zu speichern,
ohne diese in Text Datentypen konvertieren zu müssen.

Anhand eines Praxisbeispiels wird im Weiteren die Funktionsweise des Systems in Hinblick auf das Hinzufügen neuer Daten
unter gewährleistung der Typsicherheit verdeutlicht.

\section{Praxisbeispiel}
\label{sec:requirements:example}

Typsicherheit ist gegeben, wenn Server und Client mit exakt den
selben Typdefinitionen arbeiten. Dafür sind mehrere Schritte erforderlich.
Die Reihenfolge der nachfolgend aufgeführten Schritte ergibt sich aus dem bisherigen Entwicklungsprozess.

\subsection{Anlegen des Typescript Interfaces}
\label{sec:requirements:example:interface}

Als erstes wird ein Typescript Interface für den Datensatz erstellt, der abgebildet werden soll.
Wir erweitern den Datentyp \emph{Project}~\ref{fig:basics:graphql:3} erneut:

\begin{lstlisting}[language=JavaScript,float=h!,caption={TypeScript Interface für die Darstellung eines Projektes}, label={lst:example:projectdesc}]
export interface Project {
    id: string;
    name:string;
    public: boolean;
    slug?: string;
    userId?: string;
    createdAt?: string;
    updatedAt?: string;
}
\end{lstlisting}

\begin{itemize}
    \setlength\itemsep{-1em}
    \item \emph{id/name/public}: siehe~\ref{fig:basics:graphql:3}.
    \item \emph{slug}: ist ein aus einem oder wenigen Wörtern bestehender benutzer- und suchmaschinenfreundlicher
    Text (sprechender Name) als Bestandteil einer URL~\cite{slug-wikipedia}. Diese Angabe ist optional.
    \item \emph{userId}: ist die ID des Nutzers dem dieses \emph{Project} zugeordnet ist (Fremdschlüsselbeziehung).
    \item \emph{createdAt}: ist die optionale zeitliche Angabe wann dieses \emph{Project} erstellt wurde.
    \item \emph{updatedAt}: ist die optionale zeitliche Angabe wann dieses \emph{Project} zuletzt verändert wurde.
\end{itemize}

Wird dieser Datensatz vom Server abgefragt, so lässt sich die Antwort des Servers auf eine Variable mit dem Typ \emph{Project} zuweisen.
Dadurch wird zur Kompilierzeit ermöglicht typsicher auf die einzelnen Felder des Interfaces zugreifen zu können.

Im nächsten Schritt wird das Interface dem Server zur Verfügung gestellt.

%List Interface/Response Interface
%Dokument Interface
\subsection{Generierung der JSON Schema Definitionen}
\label{sec:requirements:example:schema}
Um das Interface~\ref{lst:example:projectdesc} serverseitig nutzen zu können wird eine JSON Schema Datei generiert.
Dafür ist ein Eintrag in einem Makefile nötig, welches sich um die Generierung aller JSON Schema Dateien,
die relevant für den Server sind, kümmert.

\begin{lstlisting}[float=h!,caption={TypeScript Interface für die Project Darstellung in einer Liste}, label={lst:example:makefile}]
Project.json : $(SRC_PATH)/shared/project.ts
$(CONVERT_COMMAND)
\end{lstlisting}

Mithilfe der Schema Datei können dann Datensätze nach Abruf aus der Datenbank validiert werden.

\subsection{Anlegen des Models in Rails}
\label{sec:requirements:example:model}

Sollte das Interface~\ref{lst:example:projectdesc} nicht nur ein Subtyp eines bestehende Datentyps sein,
sondern einer neuen Datenbanktabelle entsprechen, muss eine Active Record Migration erstellt werden,
um das Datenbankschema erweitern zu können~\cite{rails-migration}.

\begin{lstlisting}[language=Ruby,float=h!,caption={Rails Migration zum hinzufügen einer \emph{projects} Datenbanktabelle}, label={lst:example:migration}]
create_table "projects", id: :uuid, default: -> { "gen_random_uuid()" }, force: :cascade do |t|
    t.string "slug"
    t.hstore "name", default: {}, null: false
    t.uuid "user_id"
    t.datetime "created_at", null: false
    t.datetime "updated_at", null: false
end
\end{lstlisting}

Hierdurch~\ref{lst:example:migration} wird eine neue Tabelle mit der Bezeichnung \emph{projects} erstellt.
Hinzukommend wird ein Active Record Model benötigt, dem die \emph{projects}-Tabelle zugeordnet wird.
Das lässt sich realisieren, indem eine Ruby Klasse mit dem selben Namen wie die Tabelle erstellt wird und
von der Klasse ApplicationRecord erbt.
Die Rails Konvention sieht vor das Datenbanktabellen im Plural und das dazugehörige Model im Singular benannt wird~\cite{rails-naming-convention}.

\begin{lstlisting}[language=Ruby,float=h!,caption={Model}, label={lst:example:model}]
class Project < ApplicationRecord
    # The owner if this project
    belongs_to :user
end
\end{lstlisting}

Auf diese Weise entsteht die Möglichkeit, die Spalten jeder Zeile in dieser Tabelle mit den Attributen der Instanzen des Models abzubilden.
Jede Zeile dieser Tabelle stellt also ein bestimmtes "Projekt" mit den in \fullref{sec:requirements:example:interface} aufgeführten Feldern dar.

Um nun auf Anfragen reagieren und Daten aus Model Instanzen an den Client liefern zu können bedarf es einem Controller.

\subsection{Anlegen eines Controllers in Rails}
\label{sec:requirements:example:controller}
Controller haben die Aufgabe Anfragen zu verarbeiten, die vom Router~\ref{lst:example:router} an sie weitergeleitet wurden.
Die Funktionen innerhalb eines Controllers sind dafür verantwortlich den Anfragen einen "Sinn" zu geben und die entsprechende Antwort zu erzeugen.
Bei einer Anfrage die Projekt-Daten ausgeliefert bekommen soll, kümmert die Controller Funktion sich darum alle Daten aus dem \emph{Project}-Model
zu holen und gibt diese dann wie bei REST APIs üblich in JSON Form zurück.

\begin{lstlisting}[language=Ruby,float=h!,caption={Route entspricht URL '/project/' und leitet Anfrage an die ProjectsController Funktion \emph{index} weiter }, label={lst:example:router}]
scope 'project' do
    get '/', controller: 'projects', action: :index
end
\end{lstlisting}

\begin{lstlisting}[language=Ruby,float=h!,caption={Controller mit Funktion zum zurückgeben aller Project Instanzen}, label={lst:example:controller}]
class ProjectsController < ApplicationController
    def index
      render json: Project.all
    end
end
\end{lstlisting}

In Zeile 3 des Controllers~\ref{lst:example:controller} werden alle Projekte aus der Datenbank geladen und in JSON Form
zurück gegeben. Um gewährleisten zu können, das die Antwort vom Server auch die erwarteten Daten liefert, wird ein
Test geschrieben der prüft, ob die Antwort dem clientseitig erstellten Interface~\ref{lst:example:projectdesc} entspricht.

\begin{lstlisting}[language=Ruby,float=h!,caption={Test überprüft, ob bei Anfrage der Route '/project/' eine Antwort vom Typ Project folgt}, label={lst:example:controller-test}]
it 'lists a single project' do
    FactoryBot.create(:project, :public)
    get "/project/"

    expect(response).to have_http_status(200)

    parsed = JSON.parse(response.body)
    expect(parsed['data'].length).to eq 1

    # Validierung gegen  das "Project" interface
    expect(parsed['data'][0]).to validate_against "Project"
end
\end{lstlisting}

Das kann in Ruby zum Beispiel mit einem JSON Schema Validator~\cite{json-schemer} erreicht werden (Zeile 9).
Nun hat der Server die Fähigkeit auf eine Anfrage nach allen Projekten unter Gewährleistung der Typsicherheit zu reagieren.
Somit muss der Client noch die Möglichkeit erhalten eine Anfrage zu erstellen und die Antwort grafisch abbilden zu können.

%Für jede Sicht (z.B. Admin/Frontend) eine Route und Controller Funktion.
\subsection{DataServices auf dem Client}
\label{sec:requirements:example:service}
In der Welt von Angular gibt es eine strikte Trennung zwischen Darstellung und Verarbeitung von Daten~\cite{angular-service}.
Für die Verarbeitung von Daten, wie das Abrufen, werden Angular Services genutzt. Diese sind typischerweise Typescript Klassen,
mit genau definierten Nutzungsmöglichkeiten. Der im Folgenden beschriebene Service hat die Aufgabe Projekt-Daten zu verarbeiten.

\begin{lstlisting}[language=JavaScript,float=h!,caption={Funktion zum Abruf aller Projekte vom Server}, label={lst:example:service}]
@Injectable()
export class ProjectsDataService {
    constructor(private http: HttpClient) { }
    getProjects() {
        // Die Antwort soll dem Typparameter "Project" entsprechen
        return this.http.get<Project>('/project/');
    }
}
\end{lstlisting}

\begin{itemize}
    \setlength\itemsep{-1em}
    \item \emph{Zeile 1}: \emph{@Injectable} stellt sicher, dass der Compiler die notwendigen Metadaten erzeugt, um die Abhängigkeiten der Klasse zu erstellen, wenn die Klasse injiziert wird.
    \item \emph{Zeile 2}: Deklarierung der Klasse/des Services ProjectsDataService
    \item \emph{Zeile 3}: Injizierung des HttpClient~\cite{angular-http} in den Service
    \item \emph{Zeile 4}: Methode zum abfragen von Projekt-Daten
    \item \emph{Zeile 6}: Nutzung des HttpClient zur Erstellung eines typisierten HTTP-Requests, welcher zur bereits hinzugefügten Route~\ref{lst:example:router} führt.
\end{itemize}

Die Angabe des Antworttyps \emph{Project} in Zeile 6 fungiert dabei zur Kompilierungszeit als Type Assertion~\cite{typescript-typeassertion}
und erleichtert den Zugriff auf die Attribute der Antwort. Der TypeScript Compiler führt während der Laufzeit jedoch keine Überprüfung durch.
Er geht an dieser Stelle davon aus, das der Entwickler spezielle Prüfungen, wie z.B. der Test ~\ref{lst:example:controller-test}, durchgeführt hat.

Die Dartsellung der erhaltenen Daten übernehmen dann Angular Komponenten, in die Services "injiziert" werden können.
Dadurch können Komponenten die Funktionen eines injizierten Services nach Belieben nutzen.

\subsection{Komponenten auf dem Client}
\label{sec:requirements:example:component}

\begin{lstlisting}[language=JavaScript,float=h!,caption={Funktion zum Abruf aller Projekte vom Server}, label={lst:example:service}]
@Component({
    selector: "project-list",
    templateUrl: "templates/project-list.html",
})
export class ProjectListComponent {
    // Injizierung des ProjectsDataService
    constructor(private _projectsData: ProjectsDataService) {}

    readonly projects = this._projectsData.getProjects();
}
\end{lstlisting}
Eine Angular Komponente entspricht einem Teilbaum des DOM-Baums, der auch View genannt wird und erhält somit einen genau definierten Zweck.
In unserem Fall wird die Komponente zur grafischen Auflistung der Projekt-Daten genutzt, was wie folgt umgesetzt wurde:

\begin{itemize}
    \setlength\itemsep{-1em}
    \item \emph{Zeile 1}: Annotierung einer Typescript-Klasse als Komponente
    \item \emph{Zeile 2}: Der Wert von \emph{selector} kann als HTML-Tag (<project-list></project-list>) in Templates genutzt werden,
    um diese Komponente Instanziieren und das zugehörige Template innerhalb des Bezeichners rendern zu können
    \item \emph{Zeile 3}: Festlegung des Pfades, wo sich das zu rendernde Template, also der darzustellende HTML Code befindet
    \item \emph{Zeile 4}: Deklarierung der Klasse/des Komponente ProjectListComponent
    \item \emph{Zeile 6}: Injizierung des ProjectsDataService~\cite{angular-http} in die Komponente
    \item \emph{Zeile 8}: Nutzung des ProjectsDataService zum Abrufen der Projekt-Daten
\end{itemize}

Das zugehörige Template project-list.html sieht folgendermaßen aus:

\begin{lstlisting}[language=JavaScript,float=h!,caption={Funktion zum Abruf aller Projekte vom Server}, label={lst:example:service}]
<project-list-item
  *ngFor="let project of projects | async"
  [project]="project"
></project-list-item>
\end{lstlisting}

\begin{itemize}
    \setlength\itemsep{-1em}
    \item \emph{Zeile 1}: Aufruf der Komponente mit dem \emph{selector} "project-list-item".
    Diese übernimmt hier die Darstellung eines einzelnen Projektes innerhalb einer Liste und verdeutlicht damit
    die Modularität von Angular Komponenten.
    \item \emph{Zeile 2}: *ngFor ist die "Repeater"-Direktive ~\cite{ng-for} in Angular.
    Sie ermöglicht ein gegebenes HTML Template einmal für jeden Wert in einem Array zu wiederholen,
    wobei jedes Mal der Array-Wert als Kontext übergeben wird.
    \item \emph{Zeile 3}: Übergibt den Wert aus dem Array an eine mit \emph{@Input()} annotierte Variable \emph{project} aus der "project-list-item" Komponenten.
\end{itemize}

\subsection{Neue Sicht}
\label{sec:requirements:example:newview}

Für das Bereitstellen einer neuen Sicht auf die Projekt Daten müssen mehrere der Schritte wiederholt werden.
In der Tabelle \ref{tbl:newview} wird aufgeführt welche Schritte in welchem Ausmaß ausgeführt werden müssen.

\begin{table}[h]
    \begin{tabular}{|p{0.12\textwidth}|p{0.52\textwidth}|p{0.12\textwidth}|p{0.12\textwidth}|}
        \hline
        \textbf{Schritt} & \textbf{Beschreibung} & \textbf{Aktuelles \newline System} & \textbf{GraphQL} \\ \hline
        $\ref{sec:requirements:example:interface}$ & Anlegen eines Interfaces & $\surd$ &  $X$ \\ \hline
        $\ref{sec:requirements:example:schema}$ & Eintrag in Makefile & $\surd$ &  $X$ \\ \hline
        $\ref{sec:requirements:example:model}$ & Anlegen des Models & $X$ &  $X$ \\ \hline
        \multirow{3}{*}{$\ref{sec:requirements:example:controller}$}
        & Route definieren & $\surd$ &  $X$ \\
        & Anlegen des Controllers & $X$ &  $X$ \\
        & Controller Funktion schreiben & $\surd$ &  $X$ \\ \hline
        $\ref{sec:requirements:example:service}$ & Anlegen eines Angular Services & $\surd$ &  $X$ \\ \hline
        $\ref{sec:requirements:example:component}$ & Anlegen einer Angular Komponenten & $\surd$ &  $\surd$ \\ \hline
    \end{tabular}
    \vspace{5pt}
    \caption{Vergleich der Funktionweise des aktuellen Systems mit GraphQL in Bezug auf die Erstellung neuer Sichten auf bereist vorhandene Datensätze}
    \label{tbl:newview}
\end{table}

Auffallend ist, dass GraphQL nur eine dezimiertere Menge an Schritten benötigt. Das resultiert aus der Funktionsweise von GraphQL,
da zu beginn lediglich ein Typ (hier: \emph{project}) definiert werden muss der alle Felder beinhaltet die der Client braucht.
Um eine spezielle Sicht auf den Datentyp in Form einer Teilmenge der vorhandenen Felder zu erlangen wird eine Anfrage geschrieben, die
nur die benötigten Felder beinhaltet. Mithilfe eines Codegenerators lässt sich aus der Anfrage ein Typescript Interface und ein Angular Service,
dem eine Funktion zum abschicken der Anfrage beigefügt wird, generieren.
Somit werden die Schritte "Anlegen eines Interfaces" und "Anlegen eines Angular Services" obsolet.
Zudem gibt es nur eine Route und Controller Funktion auf dem Server, nachfolgend Endpunkt genannt, der alle GraphQL Anfragen entgegen nimmt
und an den GraphQL Server weiterleitet. Dort werden Datenbank Abfragen automatisch zusammengestellt und die Antwort an die Controller Funktion zurück gegeben.
Somit sind die Schritte aus \fullref{sec:requirements:example:controller} und \fullref{sec:requirements:example:service} ebenfalls obsolet.

Die genaue Funktionsweise des Codegenerators lässt sich anhand eines Beispiels simplifizieren ~\fullref{sec:requirements:example:autogeneration}.

\subsection{Automatische Generierung von JSON Schema Definitionen}
\label{sec:requirements:example:autogeneration}


export const ProjectsDocument = gql`
query Projects {
    projects {
        nodes {
            id
            name
        }
    }
}
`;

@Injectable({
    providedIn: "root",
})
export class ProjectsGQL extends Apollo.Query<
ProjectsQuery,
ProjectsQueryVariables
> {
    document = ProjectsDocument;
    constructor(apollo: Apollo.Apollo) {
        super(apollo);
    }
}

export type ProjectsQuery = { __typename?: "Query" } & {
    projects: { __typename?: "ProjectConnection" } & {
        nodes?: Maybe<
        Array<Maybe<{ __typename?: "Project" } & Pick<Project, "id" | "name">>>
        >;
    };
};

export type ProjectsQueryVariables = {};


Anhand von Beispiel: Übersicht über alle

\section{Anforderungen}
\label{sec:requirements:req}

\subsection{Darstellungsvielfalt}
Nutzerbereich:
Kacheldarstellung auf der Landingpage benötigt weniger Informationen als geliefert werden.
Adminbereich:
Tabellen Übersicht benötigt weniger Daten. Editierung benötigt alle Daten.
Mehrere Requests für einen View

\subsection{End-to-end Typsicherheit}
An dieser Stelle könnte eine Typüberprüfung durchgeführt werden. Ein Nachteil der sich daraus ergibt ist das jedes mal wenn ein Objekt
mit Daten an den Client geschickt wird, alle Attribute dieses Objekts validiert werden müssen. Das führt zu zusätzlichem Berechnungsaufwand.

Erfordert applikationsübergreifende Typdefinitionen.
JSON Schema Validator für Datenbankfelder:
/models/json schema validator
JSON Schema Validator für Requests:
grammars controller update
JSON Schema Validator für Responses:
Rspec
JSON Schema Erzeugung aus Typescript Interfaces:
Aktuell werden Clientseitig JSON Schema Dateien mithilfe von Typescript Interfaces und einem ellenlangen Makefile generiert.

\section{Vorteile des bisherigen Ansatzes}
\section{Nachteile des bisherigen Ansatzes}
\subsection{Auswahl von Attributen}
\subsection{Request und Response Typen}
\subsection{JSON Schema Generierung per Makefile}
Ein Interface pro Anfrage und Antwort erstellen. Pro Interface Eintrag in Makefile.

\section{Typsicherheit}
Typsicherheit muss auf dem Client, wie auf dem Server und in der Datenbank gewährleistet sein. Schreibt ein Programmierer einen neuen Request an den Server,
muss zur Kompilierung auffallen, sollte dieser nach Datenfeldern fragen, die es nicht gibt.

\section{Typdefinition - Server}
Typschema Definition.

\subsection{Datenbankschema}
Muss mit dem Schema übereinstimmen. Möglichkeit der Generierung höchstwahrscheinlich nicht gegeben.
\subsection{JSON Blob Validierung}
Hierbei werden CLientseitige Typdefinitionen benötigt. Möglicher einbau in das serverseitige Schema?

\section{Typdefinition - Client}
\subsection{Codegenerierung}
In diesem Kapitel möchte ich darauf eingehen, dass die Generierung von Clientseitigen Typescript Interfaces z.B. eine Anforderung darstellt, 
da es sich andernfalls kaum vom derzeitigen Lösungsansatz unterscheiden wird. 


\section{Synchronisation der Typdefinitionen}
Zu jedem Zeitpunkt müssen alle Datentypen, ob Server, Client oder Datenbank synchron zu einander sein oder per resolvern umgewandelt werden.

\section{Darstellungsflexibilität}
Nicht mehr Daten als benötigt.
\subsection{Pagination}
Auslieferung von reduzierter Mengen an Daten.
\subsection{Mehrsprachigkeit}

\section{Performance}
Nur ein Request pro Seitenaufruf. Bsp news overview. Effiziente Datenbankqueries.

\section{Skalierbarkeit}

\section{Sonderanforderungen}
\subsection{Schlüsselkonvention - Camelcase/Snakecase}
Angular Client zu Ruby Server kämpfen mit verschiedenen Konvetionen.
\subsection{Mehrsprachigkeit}
Mehrere Sprachen müssen abbildbar sein und in Datenbank gespeichert werden.
\section{Balanced Scorecard Kriterien}
balanced Scoreboard gewichtung der kriterien und formulierung
\chapter{Evaluation von Server Roundtrip Verfahren}

\section{Fast JSON API}
\subsection{Graphiti}
https://www.graphiti.dev/guides/
\subsection{JSON API Scorecard}
\section{GraphQL}
\subsection{Schema-first}
GraphQL Schema in SDL geschrieben. Resolvers für übersetzung zu anderen sprachen etc.
\subsection{Modularisierung}
feature brands?
Eine Datei pro Typ?
Eine große schema Datei?
\subsection{Codeverdoppelung}
Bei der Pagination.
\subsection{Code-first}
Nutzung von gapqhl-ruby
https://github.com/rmosolgo/graphql-ruby
\subsection{GraphQL Scorecard}
\section{Optimierung der bestehenden Lösung - make or buy}
Narrow-Funktion um nur einen Request pro Seitenaufruf ermöglichen zu können. JSON Api Konzept wird dabei teilweise genutzt.
\section{Zusätzliche Verfahren}
\subsection{Deepr}
Gibt es nur in Javascript.
https://github.com/deeprjs/deepr
\subsection{Deepr Scorecard}
\section{Balanced Scorecard}
\chapter{Implementierung}

\chapter{Fazit}
\section{Erreichte Ziele}
\section{Nicht erreichte Ziele}
\section{Ausblick}
Server Round Trip mit TCP messen nicht mit ICMP. Tracer middleware
